{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import pairwise_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CUB/gpt_res_cleaning.pkl', 'rb') as fp:\n",
    "    gpt_res_cleaning = pkl.load(fp)\n",
    "\n",
    "with open('CUB/gpt_res_generation.pkl', 'rb') as fp:\n",
    "    gpt_res_generation = pkl.load(fp)\n",
    "\n",
    "with open('CUB/gpt_res_gen_patch.pkl', 'rb') as fp:\n",
    "    gpt_res_gen_patch = pkl.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = dict()\n",
    "for part_res in gpt_res_cleaning:\n",
    "    part_name, part_res_parsed = part_res['part_name'], json.loads(part_res['response'])\n",
    "    to_remove, merge2dups = part_res_parsed['remove'], part_res_parsed['merge']\n",
    "    merge = dict()\n",
    "    for merge_to, duplicates in merge2dups.items():\n",
    "        merge.update({d: merge_to for d in duplicates})\n",
    "    mappings[part_name] = (to_remove, merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def clean_concepts(concept_dict: dict):\n",
    "    if all(type(cpt_list) is list for cpt_list in concept_dict.values()):\n",
    "        return concept_dict\n",
    "    cleaned_concept_dict = dict()\n",
    "    # Here concepts is a dict of str or list\n",
    "    for part_name, concepts in concept_dict.items():\n",
    "        cleaned_concepts = []\n",
    "        cleaned_concepts += itertools.chain(*[v if type(v) is list else [v]for v in concepts.values()])\n",
    "        cleaned_concept_dict[part_name] = cleaned_concepts\n",
    "    \n",
    "    return cleaned_concept_dict\n",
    "\n",
    "patch_dict = {patch_res['class_name']: patch_res['response'] for patch_res in gpt_res_gen_patch}\n",
    "\n",
    "concepts_cleaned = dict()\n",
    "for class_res in gpt_res_generation:\n",
    "    class_name, class_concepts = class_res['class_name'], json.loads(class_res['response'])\n",
    "    if class_name in patch_dict:\n",
    "        class_concepts = json.loads(patch_dict[class_name])\n",
    "    class_concepts = clean_concepts(class_concepts)\n",
    "    class_cpts_processed = dict()\n",
    "    for part_name, (removes, merges) in mappings.items():\n",
    "        original_cpts = class_concepts[part_name]\n",
    "        filtered_cpts = [cpt for cpt in original_cpts if cpt not in removes]\n",
    "        mapped_concepts = [merges.get(cpt, cpt) for cpt in filtered_cpts]\n",
    "        class_cpts_processed[part_name] = mapped_concepts\n",
    "    # print(class_name)\n",
    "    # print({k: len(v) for k, v in class_cpts_cleaned.items()})\n",
    "    # Deal with responses that do not follow format\n",
    "    counts = {k: len(v) for k, v in class_cpts_processed.items()}\n",
    "    if any(v == 0 for v in counts.values()):\n",
    "        print(class_name)\n",
    "        print(counts)\n",
    "        print(class_concepts)\n",
    "    concepts_cleaned[class_name] = class_cpts_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concepts_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CUB/concepts_processed.json', 'w') as fp:\n",
    "    json.dump(concepts_cleaned, fp=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('CUB/gpt_res_gen_patch.pkl', 'rb') as fp:\n",
    "    gpt_res_gen_patch = pkl.load(fp)\n",
    "gpt_res_gen_patch[0]['class_name'] = 'Prairie Warbler'\n",
    "gpt_res_gen_patch\n",
    "\n",
    "\n",
    "with open('CUB/gpt_res_gen_patch.pkl', 'wb') as fp:\n",
    "    pkl.dump(gpt_res_gen_patch, file=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion_cub(client, example_class_name: str, example_answer: str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant designed to provide visual features of different species of birds and output them in JSON.\"},\n",
    "        \n",
    "        {\"role\": \"user\",\n",
    "        \"content\": (f\"To visually identify {example_class_name}, please provide 3 most common characteristics of each of {example_class_name}'s parts \"\n",
    "                    \"(head, beak, tail, wing, eye, leg, torso) in shape, color, or size:\")},\n",
    "        \n",
    "        {\"role\": 'assistant', \"content\": example_answer},\n",
    "        \n",
    "        {\"role\": \"user\",\n",
    "        \"content\": (f\"To visually identify Prairie Warbler, please provide 3 most common characteristics of each of Prairie Warbler's parts \"\n",
    "                    \"(head, beak, tail, wing, eye, leg, torso) in shape, color, or size:\")}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "with open('CUB/example_generation.json', 'r') as fp:\n",
    "    example = json.load(fp=fp)\n",
    "\n",
    "example_class_name, example_answer = example['class'], json.dumps(example['concepts'])\n",
    "response = chat_completion_cub(client, example_class_name, example_answer)\n",
    "\n",
    "print(response)\n",
    "\n",
    "patches = [dict(class_name=example_class_name, response=response)]\n",
    "with open('CUB/gpt_res_gen_patch.pkl', 'wb') as fp:\n",
    "   pkl.dump(patches) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('CUB/gpt_res_gen_patch.pkl', 'rb') as fp:\n",
    "   patch = pkl.load(fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_res_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
