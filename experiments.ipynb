{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import timm\n",
    "import copy\n",
    "import torch\n",
    "import open_clip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import CUBDataset, get_transforms, DEFAULT_ATTR_INDICES\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartCEM(nn.Module):\n",
    "    def __init__(self, backbone='resnet50', num_concepts=112, num_classes=200) -> None:\n",
    "        super(PartCEM, self).__init__()\n",
    "        self.backbone = timm.create_model(backbone, pretrained=True)\n",
    "        self.dim = self.backbone.fc.weight.shape[-1]\n",
    "        self.concepts = nn.Parameter(torch.randn(num_concepts + 1, self.dim))\n",
    "        self.fc = nn.Linear(num_concepts, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone.forward_features(x)\n",
    "        b, c, h, w = x.shape\n",
    "        h, w = h*2, w*2\n",
    "        x = F.interpolate(x, size=(h, w), mode='bilinear') # shape: [b, c, h, w], e.g. c=2048, h=w=14\n",
    "        conv_weights = self.concepts[..., None, None] # shape: [num_concepts + 1, c, 1, 1]\n",
    "\n",
    "        score_maps = F.sigmoid(F.conv2d(x, conv_weights)) # shape: [b, num_concepts, h, w]\n",
    "        scores = F.sigmoid(score_maps.sum((-1, -2))) # shape: [b, num_concepts]\n",
    "        preds = self.fc(scores[..., :-1])\n",
    "\n",
    "        concepts_expanded = self.concepts[..., None, None].expand(-1, -1, h, w) # shape: [num_concepts, c, h, w]\n",
    "        reconstructed = torch.einsum('bkhw,kchw->bchw', score_maps, concepts_expanded) # shape: [b, c, h, w]\n",
    "\n",
    "        x = x.view(b, c, h*w).permute(0, 2, 1) # shape: [b, h*w, c]\n",
    "        reconstructed = reconstructed.view(b, c, h*w).permute(0, 2, 1) # shape: [b, h*w, c]\n",
    "\n",
    "        recon_loss = torch.sum(torch.cdist(x, reconstructed, p=2)) # shape: [h*w, h*w]\n",
    "        return scores, preds, recon_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_cem = PartCEM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, preds, recon_loss_batch = part_cem(torch.rand(32,3,448,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 113]), torch.Size([32, 200]), torch.Size([]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape, preds.shape, recon_loss_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
